{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bc2579f",
   "metadata": {},
   "source": [
    "# Preamble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46de85a2",
   "metadata": {},
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affadcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .json files\n",
    "import json\n",
    "\n",
    "# Make data frames\n",
    "import pandas as pd\n",
    "\n",
    "# Make plots\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# PCA \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# PCA, MCA, FAMD\n",
    "import prince\n",
    "\n",
    "# Suppress warnings from prince\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "\n",
    "# Timer\n",
    "import time # for debugging\n",
    "\n",
    "# Print dictionaries prettily\n",
    "import pprint\n",
    "\n",
    "# For calculations\n",
    "import numpy as np\n",
    "\n",
    "# For plots\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Measure accuracy, precision, recall\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "\n",
    "# roc curve and auc\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f25e2d",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4087b422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for reporting the time elapsed\n",
    "\n",
    "# Input is a start time and an end time\n",
    "# Output is a print statement giving the time elapsed\n",
    "def time_elapsed(start, end):\n",
    "    # Compute time elapsed in seconds\n",
    "    total_time_seconds = end-start \n",
    "    if total_time_seconds < 60:\n",
    "        print(\"Time elapsed =\",total_time_seconds, \"seconds\")\n",
    "    else:\n",
    "        # In minutes \n",
    "        total_time_minutes = total_time_seconds/60 \n",
    "        if total_time_minutes < 60: \n",
    "            print(\"Time elapsed =\", total_time_minutes, \"minutes\") \n",
    "        else: \n",
    "            # In hours\n",
    "            total_time_hours = total_time_minutes/60 \n",
    "            # Print the time elapsed in hours\n",
    "            print(\"Time elapsed =\", total_time_hours, \"hours\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a22f85f",
   "metadata": {},
   "source": [
    "### Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c90b0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add in a column to bills_df_all (in DataProcessing) with the lists of sponsors/voters by name\n",
    "# Input is a column header for a column with dictionary entries for politicians (e.g., \"sponsor(s).people\")\n",
    "# Output is the column of dictionaries turns into a column of lists\n",
    "def col_of_lists(people):\n",
    "    new_col = []\n",
    "    for i in range(len(bills_df_all)):\n",
    "        names = []\n",
    "        if type(bills_df_all.iloc[i, bills_df_all.columns.get_loc(people)]) == float:\n",
    "            names.append(\"none\")\n",
    "        elif type(bills_df_all.iloc[i, bills_df_all.columns.get_loc(people)]) == str:    \n",
    "            names.append(\"unanimous\")    \n",
    "        elif type(bills_df_all.iloc[i, bills_df_all.columns.get_loc(people)]) == list:\n",
    "            for person_dict in bills_df_all.iloc[i, bills_df_all.columns.get_loc(people)]:\n",
    "                if \"vote\" in person_dict:\n",
    "                    names.append(person_dict[\"vote\"]+\".\"+person_dict[\"name\"])\n",
    "                else:    \n",
    "                    names.append(person_dict[\"name\"])\n",
    "        new_col.append(names)        \n",
    "    bills_df_all[people] = new_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3d9e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that will one-hot a column of lists (input is a column header, \n",
    "# output is the concatenated bills_df_all (DataProcessing))\n",
    "def one_hot_col(column):\n",
    "    cols_add_dict = {}\n",
    "    all_entries = list(set([item for sublist in bills_df_all[column] for item in sublist]))\n",
    "    for entry in all_entries:\n",
    "        #start_entry = time.time() # for debugging\n",
    "        #print(entry) # for debugging\n",
    "        col_for_entry = []\n",
    "        for i in range(len(bills_df_all)):\n",
    "            if entry in bills_df_all.iloc[i, bills_df_all.columns.get_loc(column)]:\n",
    "                col_for_entry.append(1) \n",
    "            else:\n",
    "                col_for_entry.append(0)\n",
    "        cols_add_dict[column+\".\"+entry] = col_for_entry\n",
    "        #end_entry = time.time() # for debugging\n",
    "        #time_elapsed(start_entry, end_entry) # for debugging\n",
    "    df = pd.DataFrame(cols_add_dict)\n",
    "    return pd.concat([bills_df_all, df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dc5c2f",
   "metadata": {},
   "source": [
    "### Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b484f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the correlated features for the first n components of pca (don't make the number\n",
    "# too high), output is a dictionary\n",
    "def cor_feat_pca(PCA_cols, number_of_components, components_data_frame):\n",
    "    correlations_dict = {}\n",
    "    for i in range(0,number_of_components,1):\n",
    "        this_ordered = components_data_frame.sort_values(\n",
    "            by = components_data_frame.columns[i], ascending = False)\n",
    "        correlations_dict[\"Component\"+str(i+1)] = []\n",
    "        for j in range(len(PCA_cols.columns.values.tolist())):\n",
    "            correlations_dict[\"Component\"+str(i+1)].append([this_ordered.axes[0].tolist()[j], \n",
    "                round(this_ordered.iloc[j,i],3)])\n",
    "    return correlations_dict  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
